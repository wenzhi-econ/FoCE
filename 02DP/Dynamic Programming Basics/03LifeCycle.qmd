---
title: "Course 35: Stochastic LifeCycle Consumption-Savings Model: Discretized Choice Variable"
format:
    html:
        theme: cosmo
        code-fold: false 
        code-line-numbers: true
        code-copy: true
        highlight-style: github
        number-sections: true
        toc: true
        page-layout: full
        grid:
            body-width: 1000px
jupyter: python3
execute: 
    eval: true
    echo: true
---

# Stochastic LifeCycle Consumption-Savings Model

## Model

The Bellman equation is as follows:

\begin{equation}
V(M)=\max _{0 \leq c \leq M}\{u(c)+\beta \mathbb{E}_{\widetilde{R}, \widetilde{y}} V(\underbrace{\widetilde{R}(M-c)+\widetilde{y}}_{=M^{\prime}})\}
\end{equation}

-   Assume that $\widetilde{R}$ is fixed.

-   Stochastic income $\widetilde{y}$ follows a log normal distribution with $\mu=$ and $\sigma$ to be specified. Then we know that $\widetilde{y} > 0$ and $\mathbb{E}(\widetilde{y}) = \exp(\sigma^2/2)$.

-   For backward compatibility with the cake-eating example, we assume $\widetilde{y}=0$ as a special case.

## Numerical integration

The key difficulty here is that we need to calculate the expectation (over different realizations of $\widetilde{y}$) of the value function.

To do this, we use the **Gauss-Legendre Quardrature** method. Specifically, we need to select a set of discrete point of $\widetilde{y}$, along with the weights associated with each point. Then we approximate the integral by the weighted sums of value function evaluated at these $\widetilde{y}$.

Again, like in the cake-eating problem, we build up the next-period value function (before taking expectations) with **states in `axis=0`, choices in `axis=1`**.

But here, we need another dimension of array to store the quardrature points of $\widetilde{y}$. Notice that **we put these quardrature points in `axis=2`**, so that we can utilize a special feature of the `np.dot()` function.

See [document here](https://numpy.org/doc/stable/reference/generated/numpy.dot.html#numpy.dot) which says that

> If *a* is an N-D array and *b* is a 1-D array, it is a sum product over the last axis of *a* and *b*.

To see this, we can have the following test:

```{python}
# | code-fold: true

import numpy as np 
import matplotlib.pyplot as plt 

a = np.zeros((3, 4, 2))
a[:,:,1] = np.ones((3,4))
print('a = ')
print(a)
b = np.array([0.75, 0.25])
print(f'\nb = ')
print(b)
print(f'\nnp.dot(a, b) = ')
print(np.dot(a, b))

print()
c = a.copy()
c[:,0,:] = np.ones((3,2))
print('c = ')
print(c)
print(f'\nb = ')
print(b)
print(f'\nnp.dot(c, b) = ')
print(np.dot(c, b))

print()
d = a.copy()
d[:,0,:] = np.ones((3,2))
d[:,1,:] = np.zeros((3,2))
print('d = ')
print(d)
print(f'\nb = ')
print(b)
print(f'\nnp.dot(d, b) = ')
print(np.dot(d, b))

print()
e = a.copy()
e[:,0,:] = np.ones((3,2))
e[:,1,:] = np.zeros((3,2))
e[0,:,:] = np.zeros((4,2))
print('e = ')
print(e)
print(f'\nb = ')
print(b)
print(f'\nnp.dot(e, b) = ')
print(np.dot(e, b))
```